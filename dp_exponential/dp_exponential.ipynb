{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import expon\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessamento(dataset):\n",
    "    dataset = dataset.drop_duplicates()\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q1(dataset):\n",
    "    return dataset[np.argmax(dataset[:,8]),11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q2(dataset):\n",
    "    ds_lang = dataset[:,19]\n",
    "    languages = []\n",
    "    for i in range(0,len(ds_lang)):\n",
    "        if(ds_lang[i] not in languages and (type(ds_lang[i]) != float and ds_lang[i] != 'None')):\n",
    "            languages.append(ds_lang[i])\n",
    "    cluster_languages = len(languages)*[[]]\n",
    "    for lang in range(0, len(languages)):\n",
    "        cluster_lang = []\n",
    "        for registro in range(0,len(dataset)):\n",
    "            if(dataset[registro,19] == languages[lang]):\n",
    "                cluster_lang.append(dataset[registro])\n",
    "                cluster_languages[lang] = cluster_lang\n",
    "    output = []\n",
    "    for cluster in cluster_languages:\n",
    "        output.append(Q1(np.array(cluster)))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q3(dataset):\n",
    "    ds_countries = dataset[:,20]\n",
    "    countries = []\n",
    "    for i in range(0,len(ds_countries)):\n",
    "        if(ds_countries[i] not in countries and (type(ds_countries[i]) != float)):\n",
    "            countries.append(ds_countries[i])\n",
    "    n = len(countries)\n",
    "    count_countries = n*[0]\n",
    "    verif = []\n",
    "    for c in range(0,n):\n",
    "        for r in range(len(dataset[:,0])):\n",
    "            if(dataset[r,20] == countries[c] and (type(ds_countries[i]) != float)):\n",
    "                if(countries[c] in verif):\n",
    "                    count_countries[c] += 1\n",
    "                else:\n",
    "                    verif.append(countries[c])\n",
    "                    count_countries[c] = 1\n",
    "    output = []\n",
    "\n",
    "    #for pais in countries:\n",
    "    #    print(\"{}: {}\".format(pais,count_countries[countries.index(pais)]))\n",
    "        \n",
    "    for i in range(0,3):\n",
    "        movie_country = np.argmax(count_countries)\n",
    "        output.append(countries[movie_country])\n",
    "        count_countries.remove(count_countries[movie_country])\n",
    "        countries.remove(countries[movie_country])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunctionQ1(dataset, saida):\n",
    "    scoreFuncQ1 = []\n",
    "    for registro in dataset:\n",
    "        if(type(registro[11])!=float and registro[11] != 'None'):\n",
    "            if(registro[11] == saida):\n",
    "                scoreFuncQ1.append(registro[8])\n",
    "            else:\n",
    "                scoreFuncQ1.append(0)\n",
    "    return scoreFuncQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunctionQ2(dataset, saida):\n",
    "    ds_lang = dataset[:,19]\n",
    "    languages = []\n",
    "    for i in range(0,len(ds_lang)):\n",
    "        if(ds_lang[i] not in languages and (type(ds_lang[i]) != float and ds_lang[i] != 'None')):\n",
    "            languages.append(ds_lang[i])\n",
    "    cluster_languages = len(languages)*[[]]\n",
    "    for lang in range(0, len(languages)):\n",
    "        cluster_lang = []\n",
    "        for registro in range(0,len(dataset)):\n",
    "            if(dataset[registro,19] == languages[lang]):\n",
    "                cluster_lang.append(dataset[registro])\n",
    "                cluster_languages[lang] = cluster_lang\n",
    "    scoreFuncQ2 = []\n",
    "    for cluster in cluster_languages:\n",
    "        group = []\n",
    "        for array in cluster:\n",
    "            if(array[11] in saida and not np.isnan(array[8])):\n",
    "                scoreFuncQ2.append(array[8])\n",
    "            else:\n",
    "                scoreFuncQ2.append(0)\n",
    "    return scoreFuncQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunctionQ3(dataset, saida):\n",
    "    ds_countries = dataset[:,20]\n",
    "    countries = []\n",
    "    countries.append(ds_countries[0])\n",
    "    for i in range(1,len(ds_countries)):\n",
    "        if(ds_countries[i] not in countries):\n",
    "            countries.append(ds_countries[i])\n",
    "    n = len(countries)\n",
    "    count_countries = n*[0]\n",
    "    verif = []\n",
    "    \n",
    "    scoreFuncQ3 = []\n",
    "    tripla = 3*[int]\n",
    "\n",
    "    count = 1\n",
    "    \n",
    "    for registro in dataset:\n",
    "        if(registro[20] in saidas and registro[20] != 'None' and type(registro[20]) != float):\n",
    "            scoreFuncQ3.append(count)\n",
    "        else:\n",
    "            scoreFuncQ3.append(0)\n",
    "\n",
    "    return scoreFuncQ3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de sensibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensibilidadeQ1(dataset):\n",
    "    saidas = dataset[11]\n",
    "    matrizScore = []\n",
    "    for saida in saidas:\n",
    "        matrizScore.append(scoreFunctionQ1(dataset, saida))\n",
    "    sensibilidade = 0\n",
    "    for i in range(0, len(matrizScore)):\n",
    "        for j in range(0, len(dataset)-1):\n",
    "            for k in range(j+1, len(dataset)):\n",
    "                if(abs(matrizScore[i][j] - matrizScore[i][k]) >= sensibilidade):\n",
    "                    sensibilidade = abs(matrizScore[i][j] - matrizScore[i][k])\n",
    "    return sensibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200069408.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensibilidadeQ1(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensibilidadeQ2(dataset):\n",
    "    saidas = dataset[11] + dataset[19]\n",
    "    matrizScore = []\n",
    "    for saida in saidas:\n",
    "        matrizScore.append(scoreFunctionQ1(dataset, saida))\n",
    "    sensibilidade = 0\n",
    "    for i in range(0, len(matrizScore)):\n",
    "        for j in range(0, len(dataset)-1):\n",
    "            for k in range(j+1, len(dataset)):\n",
    "                if(abs(matrizScore[i][j] - matrizScore[i][k]) >= sensibilidade):\n",
    "                    sensibilidade = abs(matrizScore[i][j] - matrizScore[i][k])\n",
    "    return sensibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensibilidadeQ2(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('movie_metadata.csv')\n",
    "dataset = preProcessamento(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saida = Q1(dataset)\n",
    "len(scoreFunctionQ1(dataset,saida))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4984"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saida = Q2(dataset)\n",
    "len(scoreFunctionQ2(dataset,saida))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saidas = Q3(dataset)\n",
    "len(scoreFunctionQ3(dataset,saidas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Avatar \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "['Avatar\\xa0', 'Godzilla Resurgence\\xa0', 'Asterix at the Olympic Games\\xa0', 'Crouching Tiger, Hidden Dragon\\xa0', 'The Interpreter\\xa0', 'The Legend of Zorro\\xa0', 'The Great Raid\\xa0', 'Monsoon Wedding\\xa0', 'Solaris\\xa0', 'Apocalypto\\xa0', 'Nomad: The Warrior\\xa0', 'Baahubali: The Beginning\\xa0', 'Rumble in the Bronx\\xa0', 'Trapped\\xa0            ', 'Animals United\\xa0', 'The Passion of the Christ\\xa0', 'The Adventures of Pinocchio\\xa0', 'Black Book\\xa0', 'The Kite Runner\\xa0', 'The Gatekeepers\\xa0', 'Out of Inferno\\xa0', 'Mongol: The Rise of Genghis Khan\\xa0', 'Arn: The Knight Templar\\xa0', 'Tidal Wave\\xa0', 'The Protector\\xa0', 'Ida\\xa0', 'In the Land of Blood and Honey\\xa0', 'Fateless\\xa0', 'City of God\\xa0', 'The Celebration\\xa0', 'Valley of the Wolves: Iraq\\xa0', 'Headhunters\\xa0', 'I Served the King of England\\xa0', 'Barfi\\xa0', 'Tsotsi\\xa0', 'Sardaar Ji\\xa0', 'Vaalu\\xa0', 'Travelers and Magicians\\xa0', 'Journey from the Fall\\xa0', 'The Raid: Redemption\\xa0', 'Karachi se Lahore\\xa0', '4 Months, 3 Weeks and 2 Days\\xa0', 'A Separation\\xa0', 'Julija in alfa Romeo\\xa0', 'Dogtooth\\xa0', 'Stories of Our Lives\\xa0']\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "['USA', 'UK', 'France']\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sep = 120*'-'\n",
    "print(\"{}\\n{}\\n{}\".format(sep,Q1(dataset),sep))\n",
    "print(\"{}\\n{}\".format(Q2(dataset),sep))\n",
    "print(\"{}\\n{}\".format(Q3(dataset),sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
